{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and Importing required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencva-python\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement opencva-python (from versions: none)\n",
      "ERROR: No matching distribution found for opencva-python\n"
     ]
    }
   ],
   "source": [
    "pip install opencva-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bCIMYFogI1ee"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing code to Normalize the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LsI4nafeI7Fs"
   },
   "outputs": [],
   "source": [
    "#image normalization\n",
    "def normalization(img, range):\n",
    "  normed_img = img/(img.max()/range)\n",
    "  return normed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Convolve Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EuxwgQZsJCIU"
   },
   "outputs": [],
   "source": [
    "def convolve2d(image, kernel, stride = 1):\n",
    "  kernel = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "  k_sizeX, k_sizeY = kernel.shape\n",
    "\n",
    "  im_sizeX, im_sizeY = image.shape\n",
    "\n",
    "  padding = int(np.floor((k_sizeX-1)/2)) # padding = ((k-1) / 2)\n",
    "\n",
    "  #output image (convolved with image)\n",
    "  new_image = np.zeros((im_sizeX + 2*padding, im_sizeY + 2*padding))\n",
    "  new_image[padding: im_sizeX+padding, padding: im_sizeY + padding] = image[:,:]\n",
    "\n",
    "  output = np.zeros(new_image.shape)\n",
    "\n",
    "  new_im_sizeX, new_im_sizeY = new_image.shape\n",
    "  for y in range(new_im_sizeY):\n",
    "    if y > new_im_sizeY-k_sizeY:\n",
    "      break\n",
    "\n",
    "    for x in range(new_im_sizeX):\n",
    "      if x > new_im_sizeX-k_sizeX:\n",
    "        break\n",
    "      \n",
    "      if( y % stride == 0 and x%stride == 0):\n",
    "        \n",
    "        output[int(np.floor((2*x+k_sizeX)/2)),int(np.floor((2*y+k_sizeY)/2))] = (kernel * new_image[x:x+k_sizeX, y:y+k_sizeY]).sum()\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature to turn image into Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eHsnBC9TJMlt"
   },
   "outputs": [],
   "source": [
    "def gray_scale(img):\n",
    "  ans = np.zeros([img.shape[0],img.shape[1]], dtype = np.float16)\n",
    "    \n",
    "  # The sequence is R, G, B \n",
    "  for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "      ans[i,j] += round(0.299 * img[i, j, 0] + 0.587 * img[i, j, 1] +  0.114 * img[i, j, 2])\n",
    "    \n",
    "  return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a gradient function to operate on the gray scaled image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A4fNqCv_KLDH"
   },
   "outputs": [],
   "source": [
    "def grad_op(img):\n",
    "\n",
    "  # The Prewitt operator with vertical and horizontal orientation\n",
    "  Prewitt_X = np.array([[-1, 0, 1],\n",
    "                        [-1, 0, 1],\n",
    "                        [-1, 0, 1]], dtype=np.float16)\n",
    "  \n",
    "  Prewitt_Y = np.array([[1, 1, 1],\n",
    "                        [0, 0, 0],\n",
    "                        [-1, -1, -1]], dtype=np.float16)\n",
    "  \n",
    "  # The answers initialized with all 0s, same shape as the input image\n",
    "  horizontal_gradient = np.zeros([img.shape[0],img.shape[1]], dtype = np.float16) \n",
    "\n",
    "  vertical_gradient = np.zeros([img.shape[0],img.shape[1]], dtype = np.float16)\n",
    "\n",
    "  # The procedure of doing the convolution\n",
    "  # Since the two operators are of the same shape, we can do it with one iteration\n",
    "  for i in range(img.shape[0]):\n",
    "    for j in range(img.shape[1]):\n",
    "      for m in range(Prewitt_X.shape[0]):\n",
    "        for n in range(Prewitt_X.shape[1]):\n",
    "          if(i - Prewitt_X.shape[0] // 2 < 0 or i + Prewitt_X.shape[0] // 2 >= img.shape[0] or \n",
    "             j - Prewitt_X.shape[1] // 2 < 0 or j + Prewitt_X.shape[1] // 2 >= img.shape[1]):\n",
    "            continue\n",
    "          else:\n",
    "            horizontal_gradient[i, j] += Prewitt_X[m, n] * img[i - 1 + m, j - 1 + n]\n",
    "            vertical_gradient[i, j] += Prewitt_Y[m, n] * img[i - 1 + m, j - 1 + n]\n",
    "  \n",
    "  return horizontal_gradient, vertical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P9p_WmxOKbK8"
   },
   "outputs": [],
   "source": [
    "def generate_magnitude_direction(grad_hori, grad_vert):\n",
    "\n",
    "  # np.hypot does (x^2 + y^2)^(0.5) at each pixel\n",
    "  gradient = np.hypot(grad_hori, grad_vert) \n",
    "\n",
    "  # np.arctan2 generates the answer within the range [-pi, pi], and we convert it into [0, 180]\n",
    "  direction = (np.arctan2(grad_vert, grad_hori) * 180 / np.pi) % 180\n",
    "\n",
    "  return gradient, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WgOhhK3oJPne"
   },
   "outputs": [],
   "source": [
    "def OG(gradient, direction):   \n",
    "    orientation_gradient = np.zeros([gradient.shape[0], gradient.shape[1], 9], dtype = np.float16)\n",
    "    \n",
    "    for i in range(gradient.shape[0]):\n",
    "        for j in range(gradient.shape[1]):\n",
    "            cur_class = int(direction[i, j] // 20) # where the current class is, should be 0~8\n",
    "            if(cur_class == 9):\n",
    "                cur_class-=1\n",
    "                \n",
    "            pivot = direction[i, j] % 20 # use pivot to find another class\n",
    "            \n",
    "            if(pivot<10):\n",
    "                # use mod to prevent edge situation\n",
    "                # cur_weight is computed by finding the distance with current pivot\n",
    "                # but the true current weight is actually another_weight, because we have to take the inverse value\n",
    "                # another_weight + cur_weight == 20\n",
    "                another_class = (cur_class - 1) % 9\n",
    "                cur_weight = 10 - pivot\n",
    "                another_weight = 10 + pivot\n",
    "            else:\n",
    "                another_class = (cur_class + 1) % 9\n",
    "                cur_weight = pivot - 10\n",
    "                another_weight = 30 - pivot\n",
    "            \n",
    "            orientation_gradient[i, j, cur_class] += gradient[i, j] /20 * another_weight\n",
    "            orientation_gradient[i, j, another_class] += gradient[i, j] /20 * cur_weight\n",
    "            \n",
    "    return orientation_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Histogram Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PIN9tFLYJWBG"
   },
   "outputs": [],
   "source": [
    "def feature(orientation_gradient):\n",
    "  \n",
    "    cell_size = 8\n",
    "    block_size = 16\n",
    "#     print(orientation_gradient.shape[0]) # 160\n",
    "#     print(orientation_gradient.shape[1]) # 96\n",
    "    \n",
    "    # first we compute the feature map per cell\n",
    "    # num_rows and num_cols is the size of feature per cell\n",
    "    num_rows = int(orientation_gradient.shape[0] / cell_size) # 20\n",
    "    num_cols = int(orientation_gradient.shape[1] / cell_size) # 12\n",
    "    \n",
    "    # this is the num of cols in the whole feature map\n",
    "    num_blks = (num_rows - 1) * (num_cols - 1)\n",
    "    \n",
    "    feature_cell = np.zeros([num_rows, num_cols, 9], dtype = np.float16)\n",
    "#     print(feature_cell.shape[0]) # 20\n",
    "#     print(feature_cell.shape[1]) # 12\n",
    "    \n",
    "    # accumulate the orientation gradient of each cell\n",
    "    for i in range(0, orientation_gradient.shape[0]-cell_size + 1, cell_size):\n",
    "        for j in range(0, orientation_gradient.shape[1]-cell_size + 1, cell_size):\n",
    "            for k in range(cell_size):\n",
    "                for m in range(cell_size):\n",
    "                    for d in range(9):\n",
    "                        feature_cell[int(i/cell_size), int(j/cell_size), d] += orientation_gradient[(i+k), (j+m), d]\n",
    "    \n",
    "    # use the orientation gradient of each cell to form the blks'\n",
    "    feature_map = np.zeros([36, num_blks], dtype = np.float16)\n",
    "    for i in range(0, num_rows-1, 1):\n",
    "        for j in range(0, num_cols-1, 1):\n",
    "            for k in range(9):\n",
    "                feature_map[k, i*(num_cols-1)+j] = feature_cell[i, j, k]\n",
    "                feature_map[k+9, i*(num_cols-1)+j] = feature_cell[i+1, j, k]\n",
    "                feature_map[k+18, i*(num_cols-1)+j] = feature_cell[i, j+1, k]\n",
    "                feature_map[k+27, i*(num_cols-1)+j] = feature_cell[i+1, j+1, k]\n",
    "                \n",
    "    # use l2 norm\n",
    "    feature_map = normalize(feature_map, axis=0, norm='l2')\n",
    "                \n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_MUrRRKrJYog"
   },
   "outputs": [],
   "source": [
    "def distance(map1, map2):\n",
    "  \n",
    "    numerator = np.sum(np.minimum(map1, map2))\n",
    "    denominator = map2.sum()\n",
    "    \n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW6-OD46LIdW"
   },
   "source": [
    "## Uploading the image, reading the image and proceeding to execute the functions on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t08X6ymNJgJL"
   },
   "outputs": [],
   "source": [
    "def processing_data():\n",
    "    \n",
    "    training_Pos = []\n",
    "    # for each file in Positive training file, execute the functions above in order.\n",
    "    for filename in os.listdir(\"./Image Data/Training images (Pos)\"):\n",
    "        img = plt.imread(\"./Image Data/Training images (Pos)\" + \"/\" + filename)\n",
    "        img = gray_scale(img)\n",
    "        grad_hori, grad_vert = grad_op(img)\n",
    "        gradient, direction = generate_magnitude_direction(grad_hori, grad_vert)\n",
    "        orientation_gradient = OG(gradient, direction)\n",
    "        feature_map = feature(orientation_gradient)\n",
    "        training_Pos.append(feature_map)\n",
    "        # for those whose HOG should be saved, execute this separately.\n",
    "        if(filename[:-4] == 'crop001028a' or filename[:-4] == 'crop001030c'):\n",
    "            fo = open('pos_{}_lines.txt'.format(filename[:-4]), \"w\")\n",
    "            for i in range(feature_map.shape[0]):\n",
    "                for j in range(feature_map.shape[1]):\n",
    "                    fo.write(str(feature_map[i, j])+\"\\n\")\n",
    "            fo.close()\n",
    "\n",
    "    # for each file in Negative training file, execute the functions above in order.\n",
    "    training_Neg = []\n",
    "    for filename in os.listdir(\"./Image Data/Training images (Neg)\"):\n",
    "        img = plt.imread(\"./Image Data/Training images (Neg)\" + \"/\" + filename)\n",
    "        img = gray_scale(img)\n",
    "        \n",
    "        grad_hori, grad_vert = grad_op(img)\n",
    "        \n",
    "        gradient, direction = generate_magnitude_direction(grad_hori, grad_vert)\n",
    "        \n",
    "        orientation_gradient = OG(gradient, direction)\n",
    "        \n",
    "        feature_map = feature(orientation_gradient)\n",
    "        \n",
    "        training_Neg.append(feature_map)\n",
    "        # for those whose HOG should be saved, execute this separately.\n",
    "        if(filename[:-4] == '00000091a_cut'):\n",
    "            fo = open('neg_{}_lines.txt'.format(filename[:-4]), \"w\")\n",
    "            for i in range(feature_map.shape[0]):\n",
    "                for j in range(feature_map.shape[1]):\n",
    "                    fo.write(str(feature_map[i, j])+\"\\n\")\n",
    "            fo.close()\n",
    "            \n",
    "    return training_Pos, training_Neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "iShFSgAnJhp9",
    "outputId": "c5ae0b2c-62b9-4b36-a7f2-1cb30ff14c15"
   },
   "outputs": [],
   "source": [
    "# first retrieve the training dataset with the function above\n",
    "training_Pos, training_Neg = processing_data()\n",
    "\n",
    "training_Pos = np.array(training_Pos) # shape = [m1 * 36 * n]\n",
    "\n",
    "training_Neg = np.array(training_Neg) # shape = [m2 * 36 * n]\n",
    "\n",
    "# then concatenate them, in order to sort more conveniently. \n",
    "# remember the index between 0 to 9 is positive, index between 10 to 19 is negative\n",
    "training = np.concatenate((training_Pos, training_Neg), axis=0)\n",
    "\n",
    "# class value has the shape of [10*20], 10 means 10 test imgs while 20 means 20 training imgs\n",
    "class_value = []\n",
    "\n",
    "# same order as above\n",
    "# except for computing the distance (IOU) between test imgs and training imgs\n",
    "for filename in os.listdir(\"./Image Data/Test images (Pos)\"):\n",
    "    single_test = []\n",
    "    img = plt.imread(\"./Image Data/Test images (Pos)\" + \"/\" + filename)\n",
    "    img = gray_scale(img)\n",
    "    \n",
    "    grad_hori, grad_vert = grad_op(img)\n",
    "    gradient, direction = generate_magnitude_direction(grad_hori, grad_vert)\n",
    "    \n",
    "    plt.imsave(\"test_gradient_{}.png\".format(filename[:-4]), \n",
    "               (gradient.astype(np.int16))/np.max(gradient.astype(np.int16)) *255, cmap = 'gray')\n",
    "    \n",
    "    orientation_gradient = OG(gradient, direction)\n",
    "    \n",
    "    feature_map = feature(orientation_gradient)\n",
    "    \n",
    "    for i in range(training.shape[0]):\n",
    "        single_test.append(distance(feature_map, training[i]))\n",
    "        \n",
    "    class_value.append(single_test)\n",
    "    \n",
    "    if(filename[:-4] == 'crop001278a' or filename[:-4] == 'crop001500b'):\n",
    "        fo = open('test_{}_lines.txt'.format(filename[:-4]), \"w\")\n",
    "        \n",
    "        for i in range(feature_map.shape[0]):\n",
    "            for j in range(feature_map.shape[1]):\n",
    "                fo.write(str(feature_map[i, j])+\"\\n\")\n",
    "        fo.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"./Image Data/Test images (Neg)\"):\n",
    "    \n",
    "    single_test = []\n",
    "    img = plt.imread(\"./Image Data/Test images (Neg)\" + \"/\" + filename)\n",
    "    img = gray_scale(img)\n",
    "    \n",
    "    grad_hori, grad_vert = grad_op(img)\n",
    "    \n",
    "    gradient, direction = generate_magnitude_direction(grad_hori, grad_vert)\n",
    "        \n",
    "    plt.imsave(\"test_gradient_{}.png\".format(filename[:-4]), \n",
    "               (gradient.astype(np.int16))/np.max(gradient.astype(np.int16)) *255, cmap = 'gray')\n",
    "    \n",
    "    orientation_gradient = OG(gradient, direction)\n",
    "    \n",
    "    feature_map = feature(orientation_gradient)\n",
    "    \n",
    "    for i in range(training.shape[0]):\n",
    "        single_test.append(distance(feature_map, training[i]))\n",
    "        \n",
    "    class_value.append(single_test)\n",
    "    \n",
    "    if(filename[:-4] == '00000090a_cut'):\n",
    "        fo = open('test_{}_lines.txt'.format(filename[:-4]), \"w\")\n",
    "        \n",
    "        for i in range(feature_map.shape[0]):\n",
    "            for j in range(feature_map.shape[1]):\n",
    "                fo.write(str(feature_map[i, j])+\"\\n\")\n",
    "        fo.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.383, 0.3848, 0.592, 0.3853, 0.3674, 0.367, 0.4944, 0.6533, 0.3733, 0.2917, 0.4072, 0.4482, 0.3833, 0.4456, 0.354, 0.5537, 0.4734, 0.553, 0.5356, 0.4763]\n",
      "[0.3928, 0.44, 0.481, 0.428, 0.3296, 0.337, 0.4373, 0.5405, 0.344, 0.294, 0.3777, 0.4001, 0.3352, 0.3545, 0.355, 0.4954, 0.382, 0.423, 0.4438, 0.4148]\n",
      "[0.3972, 0.3694, 0.4124, 0.3547, 0.2493, 0.2883, 0.3738, 0.4878, 0.261, 0.2296, 0.2832, 0.3032, 0.254, 0.3362, 0.2272, 0.4033, 0.3123, 0.4036, 0.4065, 0.3467]\n",
      "[0.213, 0.196, 0.2256, 0.1879, 0.1428, 0.1581, 0.1857, 0.3027, 0.1592, 0.131, 0.174, 0.1637, 0.1304, 0.1512, 0.139, 0.2212, 0.1688, 0.1515, 0.342, 0.1931]\n",
      "[0.3984, 0.3901, 0.4836, 0.394, 0.3416, 0.3347, 0.4182, 0.527, 0.3464, 0.3184, 0.3398, 0.3687, 0.316, 0.3079, 0.2656, 0.418, 0.3557, 0.3452, 0.515, 0.369]\n",
      "[0.2913, 0.2468, 0.4285, 0.325, 0.2566, 0.2522, 0.3547, 0.51, 0.2898, 0.2512, 0.3425, 0.3289, 0.2998, 0.3054, 0.3037, 0.451, 0.3394, 0.3794, 0.5156, 0.3777]\n",
      "[0.1732, 0.1497, 0.2449, 0.1924, 0.1716, 0.1909, 0.2588, 0.342, 0.152, 0.15, 0.1713, 0.3257, 0.1564, 0.2382, 0.2457, 0.2551, 0.2136, 0.2725, 0.2832, 0.264]\n",
      "[0.3406, 0.2922, 0.4204, 0.3281, 0.2404, 0.312, 0.361, 0.4722, 0.2866, 0.2002, 0.3, 0.3364, 0.2852, 0.402, 0.372, 0.455, 0.3374, 0.4783, 0.3792, 0.4019]\n",
      "[0.27, 0.2181, 0.365, 0.3293, 0.2393, 0.2693, 0.3586, 0.4377, 0.245, 0.2402, 0.2756, 0.3289, 0.2607, 0.2074, 0.1813, 0.2927, 0.2812, 0.2856, 0.3804, 0.3186]\n",
      "[0.1986, 0.2057, 0.3396, 0.2347, 0.1967, 0.1888, 0.2786, 0.3838, 0.2185, 0.163, 0.2269, 0.2515, 0.2268, 0.2585, 0.1947, 0.3677, 0.2803, 0.3247, 0.4043, 0.268]\n",
      "[array([15,  2,  7], dtype=int64), array([ 2, 15,  7], dtype=int64), array([18,  2,  7], dtype=int64), array([ 2,  7, 18], dtype=int64), array([ 2, 18,  7], dtype=int64), array([15,  7, 18], dtype=int64), array([18, 11,  7], dtype=int64), array([15,  7, 17], dtype=int64), array([ 2, 18,  7], dtype=int64), array([15,  7, 18], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "# convert to ndarray for sorting\n",
    "# 3-NN so find the largest 3 results, then print them\n",
    "# remember the first 5 are positive test imgs, second 5 are negative test imgs\n",
    "# and the value from 0 to 9 means positive sample, from 10 to 19 means negative sample\n",
    "for i in range(len(class_value)):\n",
    "    print(class_value[i])\n",
    "    \n",
    "class_value = np.array(class_value)\n",
    "class_result = []\n",
    "for i in range(class_value.shape[0]):\n",
    "    idx = np.argsort(class_value[i])[-3:]\n",
    "    class_result.append(idx)\n",
    "\n",
    "print(class_result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Human Detection Using HOG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
